# Node Exporter Alerts
# Pre-built alert rules for system monitoring

groups:
  #=============================================================================
  # CPU Alerts
  #=============================================================================
  - name: node:cpu
    rules:
      - alert: HostHighCpuLoad
        expr: 100 - (avg by(instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High CPU load on {{ $labels.instance }}"
          description: "CPU load is {{ $value | printf \"%.1f\" }}% (threshold: 80%)"

      - alert: HostCriticalCpuLoad
        expr: 100 - (avg by(instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 95
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "Critical CPU load on {{ $labels.instance }}"
          description: "CPU load is {{ $value | printf \"%.1f\" }}% (threshold: 95%)"

      - alert: HostCpuStealHigh
        expr: avg by(instance) (rate(node_cpu_seconds_total{mode="steal"}[5m])) * 100 > 10
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High CPU steal time on {{ $labels.instance }}"
          description: "CPU steal is {{ $value | printf \"%.1f\" }}% - VM may be overcommitted"

      - alert: HostContextSwitchingHigh
        expr: rate(node_context_switches_total[5m]) / on(instance) count by(instance) (node_cpu_seconds_total{mode="idle"}) > 10000
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High context switching on {{ $labels.instance }}"
          description: "{{ $value | printf \"%.0f\" }} context switches per CPU per second"

  #=============================================================================
  # Memory Alerts
  #=============================================================================
  - name: node:memory
    rules:
      - alert: HostMemoryLow
        expr: (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes) * 100 < 20
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Low memory on {{ $labels.instance }}"
          description: "Available memory: {{ $value | printf \"%.1f\" }}% (threshold: 20%)"

      - alert: HostMemoryCritical
        expr: (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes) * 100 < 10
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "Critical memory on {{ $labels.instance }}"
          description: "Available memory: {{ $value | printf \"%.1f\" }}% (threshold: 10%)"

      - alert: HostOomKillDetected
        expr: increase(node_vmstat_oom_kill[5m]) > 0
        for: 0m
        labels:
          severity: critical
        annotations:
          summary: "OOM kill detected on {{ $labels.instance }}"
          description: "{{ $value }} OOM kills in the last 5 minutes"

      - alert: HostMemoryUnderMemoryPressure
        expr: rate(node_vmstat_pgmajfault[5m]) > 1000
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Memory pressure on {{ $labels.instance }}"
          description: "{{ $value | printf \"%.0f\" }} major page faults per second"

      - alert: HostSwapUsageHigh
        expr: (1 - (node_memory_SwapFree_bytes / node_memory_SwapTotal_bytes)) * 100 > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High swap usage on {{ $labels.instance }}"
          description: "Swap usage: {{ $value | printf \"%.1f\" }}%"

  #=============================================================================
  # Disk Alerts
  #=============================================================================
  - name: node:disk
    rules:
      - alert: HostDiskSpaceLow
        expr: |
          (node_filesystem_avail_bytes{fstype!~"tmpfs|overlay"} / node_filesystem_size_bytes{fstype!~"tmpfs|overlay"}) * 100 < 20
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Low disk space on {{ $labels.instance }}:{{ $labels.mountpoint }}"
          description: "Available: {{ $value | printf \"%.1f\" }}% (threshold: 20%)"

      - alert: HostDiskSpaceCritical
        expr: |
          (node_filesystem_avail_bytes{fstype!~"tmpfs|overlay"} / node_filesystem_size_bytes{fstype!~"tmpfs|overlay"}) * 100 < 10
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "Critical disk space on {{ $labels.instance }}:{{ $labels.mountpoint }}"
          description: "Available: {{ $value | printf \"%.1f\" }}% (threshold: 10%)"

      - alert: HostDiskWillFillIn24Hours
        expr: |
          (node_filesystem_avail_bytes{fstype!~"tmpfs|overlay"} / node_filesystem_size_bytes{fstype!~"tmpfs|overlay"}) * 100 < 20
          and
          predict_linear(node_filesystem_avail_bytes{fstype!~"tmpfs|overlay"}[6h], 24 * 3600) < 0
        for: 30m
        labels:
          severity: warning
        annotations:
          summary: "Disk will fill in 24 hours on {{ $labels.instance }}:{{ $labels.mountpoint }}"
          description: "Filesystem predicted to run out of space within 24 hours"

      - alert: HostDiskInodesLow
        expr: (node_filesystem_files_free / node_filesystem_files) * 100 < 10
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Low inodes on {{ $labels.instance }}:{{ $labels.mountpoint }}"
          description: "Available inodes: {{ $value | printf \"%.1f\" }}%"

      - alert: HostDiskReadLatencyHigh
        expr: rate(node_disk_read_time_seconds_total[5m]) / rate(node_disk_reads_completed_total[5m]) > 0.1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High disk read latency on {{ $labels.instance }}:{{ $labels.device }}"
          description: "Read latency: {{ $value | printf \"%.3f\" }}s"

      - alert: HostDiskWriteLatencyHigh
        expr: rate(node_disk_write_time_seconds_total[5m]) / rate(node_disk_writes_completed_total[5m]) > 0.1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High disk write latency on {{ $labels.instance }}:{{ $labels.device }}"
          description: "Write latency: {{ $value | printf \"%.3f\" }}s"

  #=============================================================================
  # Network Alerts
  #=============================================================================
  - name: node:network
    rules:
      - alert: HostNetworkReceiveErrors
        expr: rate(node_network_receive_errs_total[5m]) > 1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Network receive errors on {{ $labels.instance }}:{{ $labels.device }}"
          description: "{{ $value | printf \"%.1f\" }} receive errors per second"

      - alert: HostNetworkTransmitErrors
        expr: rate(node_network_transmit_errs_total[5m]) > 1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Network transmit errors on {{ $labels.instance }}:{{ $labels.device }}"
          description: "{{ $value | printf \"%.1f\" }} transmit errors per second"

      - alert: HostNetworkInterfaceSaturated
        expr: |
          (rate(node_network_receive_bytes_total{device!~"lo|veth.*|docker.*|br.*"}[5m])
          + rate(node_network_transmit_bytes_total{device!~"lo|veth.*|docker.*|br.*"}[5m]))
          / node_network_speed_bytes{device!~"lo|veth.*|docker.*|br.*"} > 0.8
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Network interface saturated on {{ $labels.instance }}:{{ $labels.device }}"
          description: "Network utilization: {{ $value | printf \"%.1f\" }}%"

      - alert: HostNetworkBondDegraded
        expr: (node_bonding_active - node_bonding_slaves) != 0
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Network bond degraded on {{ $labels.instance }}"
          description: "Bond {{ $labels.master }} has degraded slaves"

  #=============================================================================
  # System Alerts
  #=============================================================================
  - name: node:system
    rules:
      - alert: HostSystemdServiceFailed
        expr: node_systemd_unit_state{state="failed"} == 1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Systemd service failed on {{ $labels.instance }}"
          description: "Service {{ $labels.name }} is in failed state"

      - alert: HostClockSkew
        expr: |
          (node_timex_offset_seconds > 0.05 or node_timex_offset_seconds < -0.05)
          and node_timex_sync_status != 1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Clock skew detected on {{ $labels.instance }}"
          description: "Clock offset: {{ $value | printf \"%.3f\" }}s"

      - alert: HostClockNotSynchronising
        expr: node_timex_sync_status != 1
        for: 30m
        labels:
          severity: warning
        annotations:
          summary: "Clock not synchronising on {{ $labels.instance }}"
          description: "NTP synchronisation may be broken"

      - alert: HostKernelVersionDeviationDetected
        expr: count by(kernel) (count by(instance, kernel) (node_uname_info)) > 1
        for: 1h
        labels:
          severity: info
        annotations:
          summary: "Multiple kernel versions detected"
          description: "Different kernel versions running across nodes"

      - alert: HostRebootRequired
        expr: node_reboot_required > 0
        for: 4h
        labels:
          severity: info
        annotations:
          summary: "Reboot required on {{ $labels.instance }}"
          description: "System requires a reboot (e.g., kernel update)"

      - alert: HostLoadHigh
        expr: node_load15 > count by(instance) (node_cpu_seconds_total{mode="idle"}) * 2
        for: 15m
        labels:
          severity: warning
        annotations:
          summary: "High load average on {{ $labels.instance }}"
          description: "15-minute load average: {{ $value | printf \"%.2f\" }}"

  #=============================================================================
  # Hardware Alerts
  #=============================================================================
  - name: node:hardware
    rules:
      - alert: HostEdacCorrectableErrorsDetected
        expr: increase(node_edac_correctable_errors_total[5m]) > 0
        for: 0m
        labels:
          severity: info
        annotations:
          summary: "Correctable memory errors on {{ $labels.instance }}"
          description: "{{ $value }} correctable memory errors"

      - alert: HostEdacUncorrectableErrorsDetected
        expr: increase(node_edac_uncorrectable_errors_total[5m]) > 0
        for: 0m
        labels:
          severity: critical
        annotations:
          summary: "Uncorrectable memory errors on {{ $labels.instance }}"
          description: "{{ $value }} uncorrectable memory errors - hardware issue!"

      - alert: HostRaidDegraded
        expr: node_md_disks_required - node_md_disks{state="active"} > 0
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "RAID degraded on {{ $labels.instance }}"
          description: "RAID array {{ $labels.device }} is degraded"

      - alert: HostRaidDiskFailure
        expr: node_md_disks{state="failed"} > 0
        for: 0m
        labels:
          severity: critical
        annotations:
          summary: "RAID disk failure on {{ $labels.instance }}"
          description: "RAID array {{ $labels.device }} has failed disks"

      - alert: HostConntrackLimit
        expr: node_nf_conntrack_entries / node_nf_conntrack_entries_limit > 0.8
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Connection tracking limit approaching on {{ $labels.instance }}"
          description: "Conntrack usage: {{ $value | printf \"%.1f\" }}%"
