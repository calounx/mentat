#!/bin/bash
#===============================================================================
# Configuration Management Functions
#===============================================================================

STACK_DIR="${STACK_DIR:-/opt/observability-stack}"
CONFIG_DIR="${CONFIG_DIR:-$STACK_DIR/config}"

#===============================================================================
# Configuration File Generation
#===============================================================================

generate_global_config() {
    log_step "Generating global configuration..."

    cat > "$CONFIG_DIR/global.yaml" << EOF
# Observability Stack Configuration
# Generated: $(date -Iseconds)

network:
  observability_vps_ip: "${OBSERVABILITY_IP}"
  grafana_domain: "${GRAFANA_DOMAIN:-}"
  letsencrypt_email: "${LETSENCRYPT_EMAIL:-}"

retention:
  metrics_days: ${METRICS_RETENTION_DAYS:-15}
  logs_days: ${LOGS_RETENTION_DAYS:-7}

grafana:
  admin_password: "${GRAFANA_PASSWORD}"

EOF

    if [[ "${CONFIGURE_SMTP:-false}" == "true" ]]; then
        cat >> "$CONFIG_DIR/global.yaml" << EOF
smtp:
  host: "${SMTP_HOST}"
  port: ${SMTP_PORT:-587}
  username: "${SMTP_USER}"
  password: "${SMTP_PASS}"
  from_address: "${ALERT_FROM}"
  to_addresses:
    - "${ALERT_TO}"
EOF
    fi

    chmod 600 "$CONFIG_DIR/global.yaml"
    log_success "Global configuration generated"
}

generate_host_config() {
    local host_name="$1"
    local host_ip="$2"
    shift 2
    local services=("$@")

    log_step "Generating host configuration for $host_name..."

    mkdir -p "$CONFIG_DIR/hosts"

    cat > "$CONFIG_DIR/hosts/${host_name}.yaml" << EOF
# Host Configuration: ${host_name}
# Generated: $(date -Iseconds)

host:
  name: "${host_name}"
  ip: "${host_ip}"
  environment: "production"

modules:
EOF

    for svc in "${services[@]}"; do
        cat >> "$CONFIG_DIR/hosts/${host_name}.yaml" << EOF
  ${svc}:
    enabled: true
EOF
    done

    log_success "Host configuration generated: $CONFIG_DIR/hosts/${host_name}.yaml"
}

#===============================================================================
# Prometheus Configuration
#===============================================================================

generate_prometheus_config() {
    log_step "Generating Prometheus configuration..."

    local config_file="/etc/prometheus/prometheus.yml"

    cat > "$config_file" << EOF
# Prometheus Configuration
# Generated by Observability Stack Installer
# Production-ready configuration with proper job naming

global:
  scrape_interval: 15s
  evaluation_interval: 15s
  external_labels:
    monitor: 'observability-stack'
    environment: '${ENVIRONMENT:-production}'

alerting:
  alertmanagers:
    - static_configs:
        - targets:
            - localhost:9093

rule_files:
  - /etc/prometheus/rules/*.yml
  - /etc/prometheus/rules/*.yaml
  - /etc/prometheus/alerts/*.yml
  - /etc/prometheus/alerts/*.yaml

scrape_configs:
  # ==========================================================================
  # SELF-MONITORING (Observability Stack Components)
  # ==========================================================================

  # Prometheus itself
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']
        labels:
          instance: 'observability-vps'
          component: 'prometheus'

  # Grafana metrics
  - job_name: 'grafana'
    static_configs:
      - targets: ['localhost:3000']
        labels:
          instance: 'observability-vps'
          component: 'grafana'

  # Loki metrics
  - job_name: 'loki'
    static_configs:
      - targets: ['localhost:3100']
        labels:
          instance: 'observability-vps'
          component: 'loki'

  # Tempo metrics
  - job_name: 'tempo'
    static_configs:
      - targets: ['localhost:3200']
        labels:
          instance: 'observability-vps'
          component: 'tempo'

  # Alertmanager
  - job_name: 'alertmanager'
    static_configs:
      - targets: ['localhost:9093']
        labels:
          instance: 'observability-vps'
          component: 'alertmanager'

  # Node exporter on observability VPS
  - job_name: 'observability-node'
    static_configs:
      - targets: ['localhost:9100']
        labels:
          instance: 'observability-vps'
          role: 'observability'

  # ==========================================================================
  # MONITORED HOSTS (file-based service discovery)
  # Supports both patterns: monitored-* (generic) and vpsmanager-* (CHOM)
  # Target files are auto-generated by deploy-monitored.sh on monitored nodes
  # ==========================================================================

  # Generic Monitored Node Exporter (System Metrics)
  - job_name: 'monitored-node'
    file_sd_configs:
      - files:
          - /etc/prometheus/targets/monitored-node.yaml
          - /etc/prometheus/targets/*-targets.yaml
        refresh_interval: 30s
    relabel_configs:
      - source_labels: [job]
        regex: 'monitored-node'
        action: keep

  # Generic Monitored Nginx Exporter
  - job_name: 'monitored-nginx'
    file_sd_configs:
      - files:
          - /etc/prometheus/targets/monitored-nginx.yaml
          - /etc/prometheus/targets/*-targets.yaml
        refresh_interval: 30s
    relabel_configs:
      - source_labels: [job]
        regex: 'monitored-nginx'
        action: keep

  # Generic Monitored MySQL Exporter
  - job_name: 'monitored-mysql'
    file_sd_configs:
      - files:
          - /etc/prometheus/targets/monitored-mysql.yaml
          - /etc/prometheus/targets/*-targets.yaml
        refresh_interval: 30s
    relabel_configs:
      - source_labels: [job]
        regex: 'monitored-mysql'
        action: keep

  # Generic Monitored PHP-FPM Exporter
  - job_name: 'monitored-phpfpm'
    file_sd_configs:
      - files:
          - /etc/prometheus/targets/monitored-phpfpm.yaml
          - /etc/prometheus/targets/*-targets.yaml
        refresh_interval: 30s
    relabel_configs:
      - source_labels: [job]
        regex: 'monitored-phpfpm'
        action: keep

  # Generic Monitored Fail2ban Exporter
  - job_name: 'monitored-fail2ban'
    file_sd_configs:
      - files:
          - /etc/prometheus/targets/monitored-fail2ban.yaml
          - /etc/prometheus/targets/*-targets.yaml
        refresh_interval: 30s
    relabel_configs:
      - source_labels: [job]
        regex: 'monitored-fail2ban'
        action: keep

  # ==========================================================================
  # VPSMANAGER/CHOM HOSTS (backward compatibility)
  # Legacy job naming for CHOM-provisioned VPS nodes
  # ==========================================================================

  # VPSManager Node Exporter (System Metrics)
  - job_name: 'vpsmanager-node'
    file_sd_configs:
      - files:
          - /etc/prometheus/targets/vpsmanager-node.yaml
        refresh_interval: 30s

  # VPSManager Nginx Exporter
  - job_name: 'vpsmanager-nginx'
    file_sd_configs:
      - files:
          - /etc/prometheus/targets/vpsmanager-nginx.yaml
        refresh_interval: 30s

  # VPSManager MySQL Exporter
  - job_name: 'vpsmanager-mysql'
    file_sd_configs:
      - files:
          - /etc/prometheus/targets/vpsmanager-mysql.yaml
        refresh_interval: 30s

  # VPSManager PHP-FPM Exporter
  - job_name: 'vpsmanager-phpfpm'
    file_sd_configs:
      - files:
          - /etc/prometheus/targets/vpsmanager-phpfpm.yaml
        refresh_interval: 30s

  # VPSManager Fail2ban Exporter
  - job_name: 'vpsmanager-fail2ban'
    file_sd_configs:
      - files:
          - /etc/prometheus/targets/vpsmanager-fail2ban.yaml
        refresh_interval: 30s

  # ==========================================================================
  # ALLOY TELEMETRY COLLECTOR (on observability node)
  # Scrapes metrics from the local Alloy instance
  # ==========================================================================
  - job_name: 'alloy'
    static_configs:
      - targets: ['localhost:12345']
        labels:
          instance: 'observability-vps'
          component: 'alloy'
EOF

    # Create directories
    mkdir -p /etc/prometheus/rules
    mkdir -p /etc/prometheus/alerts
    mkdir -p /etc/prometheus/targets

    # Copy alert rules
    if [[ -d "$STACK_DIR/prometheus/alerts" ]]; then
        cp "$STACK_DIR/prometheus/alerts/"*.yaml /etc/prometheus/alerts/ 2>/dev/null || true
        cp "$STACK_DIR/prometheus/alerts/"*.yml /etc/prometheus/alerts/ 2>/dev/null || true
    fi

    # Copy recording rules
    if [[ -d "$STACK_DIR/prometheus/rules" ]]; then
        cp "$STACK_DIR/prometheus/rules/"*.yaml /etc/prometheus/rules/ 2>/dev/null || true
        cp "$STACK_DIR/prometheus/rules/"*.yml /etc/prometheus/rules/ 2>/dev/null || true
    fi

    # Copy example target files
    if [[ -d "$STACK_DIR/prometheus/targets" ]]; then
        for example in "$STACK_DIR/prometheus/targets/"*.yaml.example; do
            [[ -f "$example" ]] || continue
            local target_file="/etc/prometheus/targets/$(basename "${example%.example}")"
            if [[ ! -f "$target_file" ]]; then
                cp "$example" "$target_file"
                log_info "Created target file: $target_file"
            fi
        done
    fi

    # Create empty target files if they don't exist (to prevent Prometheus errors)
    # Both monitored-* (generic) and vpsmanager-* (CHOM) patterns are supported
    for prefix in monitored vpsmanager; do
        for job in node nginx mysql phpfpm fail2ban; do
            local target_file="/etc/prometheus/targets/${prefix}-${job}.yaml"
            if [[ ! -f "$target_file" ]]; then
                cat > "$target_file" << TARGETS_EOF
# ${prefix^} ${job} targets - auto-populated by deploy-monitored.sh
# You can also manually add targets here
#
# Example:
# - targets: ['10.10.100.20:PORT']
#   labels:
#     instance: 'hostname'
#     job: '${prefix}-${job}'
#     env: 'test'
#     role: 'monitored'
TARGETS_EOF
            fi
        done
    done

    chown -R prometheus:prometheus /etc/prometheus
    log_success "Prometheus configuration generated"
}

#===============================================================================
# Loki Configuration
#===============================================================================

generate_loki_config() {
    log_step "Generating Loki configuration..."

    local config_file="/etc/loki/loki-config.yaml"
    local retention_hours=$((LOGS_RETENTION_DAYS * 24))

    mkdir -p /etc/loki /var/lib/loki

    cat > "$config_file" << EOF
# Loki Configuration
# Generated by Observability Stack Installer

auth_enabled: false

server:
  http_listen_port: 3100
  grpc_listen_port: 9096
  log_level: info

common:
  instance_addr: 127.0.0.1
  path_prefix: /var/lib/loki
  storage:
    filesystem:
      chunks_directory: /var/lib/loki/chunks
      rules_directory: /var/lib/loki/rules
  replication_factor: 1
  ring:
    kvstore:
      store: inmemory

query_range:
  results_cache:
    cache:
      embedded_cache:
        enabled: true
        max_size_mb: 100

schema_config:
  configs:
    - from: 2024-01-01
      store: tsdb
      object_store: filesystem
      schema: v13
      index:
        prefix: index_
        period: 24h

storage_config:
  filesystem:
    directory: /var/lib/loki/chunks
  tsdb_shipper:
    active_index_directory: /var/lib/loki/tsdb-index
    cache_location: /var/lib/loki/tsdb-cache

limits_config:
  retention_period: ${retention_hours}h
  ingestion_rate_mb: 16
  ingestion_burst_size_mb: 32
  max_streams_per_user: 10000
  max_global_streams_per_user: 10000
  allow_structured_metadata: true
  volume_enabled: true

pattern_ingester:
  enabled: true

compactor:
  working_directory: /var/lib/loki/compactor
  retention_enabled: true
  retention_delete_delay: 2h
  delete_request_store: filesystem

ruler:
  alertmanager_url: http://localhost:9093
EOF

    chown -R loki:loki /etc/loki /var/lib/loki
    log_success "Loki configuration generated"
}

#===============================================================================
# Grafana Configuration
#===============================================================================

generate_grafana_config() {
    log_step "Configuring Grafana..."

    local grafana_ini="/etc/grafana/grafana.ini"

    # Set admin password
    sed -i "s/^;admin_password = admin/admin_password = ${GRAFANA_PASSWORD}/" "$grafana_ini" || true

    # Configure server
    if [[ -n "${GRAFANA_DOMAIN:-}" ]]; then
        sed -i "s/^;domain = localhost/domain = ${GRAFANA_DOMAIN}/" "$grafana_ini" || true
        sed -i "s|^;root_url = .*|root_url = https://${GRAFANA_DOMAIN}|" "$grafana_ini" || true
    fi

    # Provisioning - datasources
    mkdir -p /etc/grafana/provisioning/datasources

    # Handle existing datasource configurations to prevent conflicts
    local ds_dir="/etc/grafana/provisioning/datasources"
    local our_config="$ds_dir/datasources.yaml"

    # If our config doesn't exist yet (first install)
    if [[ ! -f "$our_config" ]]; then
        log_info "First-time datasource configuration..."

        # Backup any existing files (may be from Grafana apt package or previous manual config)
        local backup_count=0
        for file in "$ds_dir"/*.yaml "$ds_dir"/*.yml; do
            [[ -f "$file" ]] || continue
            local backup="${file}.bak.$(date +%Y%m%d_%H%M%S)"
            log_info "Backing up existing config: $(basename "$file") -> $(basename "$backup")"
            mv "$file" "$backup"
            backup_count=$((backup_count + 1))
        done

        if [[ $backup_count -gt 0 ]]; then
            log_info "Backed up $backup_count existing datasource config(s)"
        fi
    else
        log_info "Updating existing datasource configuration..."
    fi

    # Create/update our datasource configuration
    cat > "$our_config" << EOF
# Grafana Datasources - Auto-provisioned by observability stack
apiVersion: 1

# Delete existing datasources to allow re-provisioning with correct UIDs
deleteDatasources:
  - name: Prometheus
    orgId: 1
  - name: Loki
    orgId: 1
  - name: Tempo
    orgId: 1
  - name: Alertmanager
    orgId: 1

datasources:
  - name: Prometheus
    type: prometheus
    uid: prometheus
    access: proxy
    url: http://localhost:9090
    isDefault: true
    editable: false
    jsonData:
      timeInterval: "15s"
      httpMethod: POST
      exemplarTraceIdDestinations:
        - name: traceID
          datasourceUid: tempo

  - name: Loki
    type: loki
    uid: loki
    access: proxy
    url: http://localhost:3100
    editable: false
    jsonData:
      maxLines: 1000
      derivedFields:
        - datasourceUid: tempo
          matcherRegex: "(?:trace_id|traceID|TraceId)[=:]\\\\s*([a-fA-F0-9]+)"
          name: TraceID
          url: "\${__value.raw}"

  - name: Tempo
    type: tempo
    uid: tempo
    access: proxy
    url: http://localhost:3200
    editable: false
    jsonData:
      httpMethod: GET
      tracesToLogs:
        datasourceUid: loki
        tags: ['host', 'job', 'service.name']
        spanStartTimeShift: '-1h'
        spanEndTimeShift: '1h'
        filterByTraceID: true
        filterBySpanID: false
      tracesToMetrics:
        datasourceUid: prometheus
        tags:
          - key: service.name
            value: job
      nodeGraph:
        enabled: true
      search:
        hide: false
      lokiSearch:
        datasourceUid: loki

  - name: Alertmanager
    type: alertmanager
    uid: alertmanager
    access: proxy
    url: http://localhost:9093
    editable: false
    jsonData:
      implementation: prometheus
      handleGrafanaManagedAlerts: true
EOF

    # Provisioning - dashboards
    mkdir -p /etc/grafana/provisioning/dashboards
    mkdir -p /var/lib/grafana/dashboards

    cat > /etc/grafana/provisioning/dashboards/default.yaml << EOF
apiVersion: 1

providers:
  - name: 'default'
    folder: ''
    type: file
    options:
      path: /var/lib/grafana/dashboards
EOF

    # Copy dashboards
    if [[ -d "$STACK_DIR/grafana/dashboards/library" ]]; then
        cp "$STACK_DIR/grafana/dashboards/library/"*.json /var/lib/grafana/dashboards/ 2>/dev/null || true
    fi
    if [[ -d "$STACK_DIR/grafana/dashboards" ]]; then
        cp "$STACK_DIR/grafana/dashboards/"*.json /var/lib/grafana/dashboards/ 2>/dev/null || true
    fi

    chown -R grafana:grafana /var/lib/grafana /etc/grafana/provisioning

    # Validate datasource configuration
    local default_count
    default_count=$(grep -c "isDefault: true" /etc/grafana/provisioning/datasources/*.yaml 2>/dev/null || echo "0")
    if [[ $default_count -gt 1 ]]; then
        log_error "Multiple datasources marked as default (found $default_count)"
        log_error "This will prevent Grafana from starting"
        return 1
    elif [[ $default_count -eq 0 ]]; then
        log_warn "No default datasource configured"
    else
        log_info "Datasource configuration validated (1 default datasource)"
    fi

    log_success "Grafana configured"
}

#===============================================================================
# Alertmanager Configuration
#===============================================================================

generate_alertmanager_config() {
    log_step "Generating Alertmanager configuration..."

    mkdir -p /etc/alertmanager

    cat > /etc/alertmanager/alertmanager.yml << EOF
# Alertmanager Configuration
# Generated by Observability Stack Installer

global:
  resolve_timeout: 5m
EOF

    if [[ "${CONFIGURE_SMTP:-false}" == "true" ]]; then
        cat >> /etc/alertmanager/alertmanager.yml << EOF
  smtp_smarthost: '${SMTP_HOST}:${SMTP_PORT}'
  smtp_from: '${ALERT_FROM}'
  smtp_auth_username: '${SMTP_USER}'
  smtp_auth_password: '${SMTP_PASS}'
  smtp_require_tls: true
EOF
    fi

    cat >> /etc/alertmanager/alertmanager.yml << EOF

route:
  group_by: ['alertname', 'severity']
  group_wait: 30s
  group_interval: 5m
  repeat_interval: 4h
  receiver: 'default-receiver'
  routes:
    - match:
        severity: critical
      receiver: 'critical-receiver'
      repeat_interval: 1h

receivers:
  - name: 'default-receiver'
EOF

    if [[ "${CONFIGURE_SMTP:-false}" == "true" ]]; then
        cat >> /etc/alertmanager/alertmanager.yml << EOF
    email_configs:
      - to: '${ALERT_TO}'
        send_resolved: true
EOF
    else
        cat >> /etc/alertmanager/alertmanager.yml << EOF
    # Email not configured - alerts will only appear in Alertmanager UI
EOF
    fi

    cat >> /etc/alertmanager/alertmanager.yml << EOF

  - name: 'critical-receiver'
EOF

    if [[ "${CONFIGURE_SMTP:-false}" == "true" ]]; then
        cat >> /etc/alertmanager/alertmanager.yml << EOF
    email_configs:
      - to: '${ALERT_TO}'
        send_resolved: true
EOF
    else
        cat >> /etc/alertmanager/alertmanager.yml << EOF
    # Email not configured
EOF
    fi

    chown -R alertmanager:alertmanager /etc/alertmanager 2>/dev/null || true
    log_success "Alertmanager configuration generated"
}

#===============================================================================
# Nginx Configuration
#===============================================================================

generate_nginx_config() {
    log_step "Generating Nginx configuration..."

    # Check if SSL is actually configured and certificates exist
    local ssl_configured=false
    if [[ "${USE_SSL:-false}" == "true" ]] && [[ -n "${GRAFANA_DOMAIN:-}" ]]; then
        if [[ -f "/etc/letsencrypt/live/${GRAFANA_DOMAIN}/fullchain.pem" ]] && \
           [[ -f "/etc/letsencrypt/live/${GRAFANA_DOMAIN}/privkey.pem" ]]; then
            ssl_configured=true
            log_info "SSL certificates found - configuring HTTPS"
        else
            log_warn "SSL enabled but certificates not found - falling back to HTTP"
        fi
    fi

    if [[ "$ssl_configured" == "true" ]]; then
        # HTTPS configuration with valid certificates
        cat > /etc/nginx/sites-available/observability << EOF
# Observability Stack Nginx Configuration (HTTPS)

server {
    listen 80;
    server_name ${GRAFANA_DOMAIN};

    location /.well-known/acme-challenge/ {
        root /var/www/html;
    }

    location / {
        return 301 https://\$server_name\$request_uri;
    }
}

server {
    listen 443 ssl http2;
    server_name ${GRAFANA_DOMAIN};

    ssl_certificate /etc/letsencrypt/live/${GRAFANA_DOMAIN}/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/${GRAFANA_DOMAIN}/privkey.pem;

    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256;
    ssl_prefer_server_ciphers off;

    # Grafana
    location / {
        proxy_pass http://127.0.0.1:3000;
        proxy_set_header Host \$host;
        proxy_set_header X-Real-IP \$remote_addr;
        proxy_set_header X-Forwarded-For \$proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto \$scheme;

        # WebSocket support
        proxy_http_version 1.1;
        proxy_set_header Upgrade \$http_upgrade;
        proxy_set_header Connection "upgrade";
    }

    # Prometheus (protected)
    location /prometheus/ {
        auth_basic "Prometheus";
        auth_basic_user_file /etc/nginx/.htpasswd;
        proxy_pass http://127.0.0.1:9090/;
    }

    # Alertmanager (protected)
    location /alertmanager/ {
        auth_basic "Alertmanager";
        auth_basic_user_file /etc/nginx/.htpasswd;
        proxy_pass http://127.0.0.1:9093/;
    }
}
EOF
    elif [[ -n "${GRAFANA_DOMAIN:-}" ]]; then
        # Domain configured but no SSL - HTTP only with domain
        cat > /etc/nginx/sites-available/observability << EOF
# Observability Stack Nginx Configuration (HTTP with domain)

server {
    listen 80;
    server_name ${GRAFANA_DOMAIN};

    # Grafana
    location / {
        proxy_pass http://127.0.0.1:3000;
        proxy_set_header Host \$host;
        proxy_set_header X-Real-IP \$remote_addr;
        proxy_set_header X-Forwarded-For \$proxy_add_x_forwarded_for;

        proxy_http_version 1.1;
        proxy_set_header Upgrade \$http_upgrade;
        proxy_set_header Connection "upgrade";
    }

    # Prometheus (protected)
    location /prometheus/ {
        auth_basic "Prometheus";
        auth_basic_user_file /etc/nginx/.htpasswd;
        proxy_pass http://127.0.0.1:9090/;
    }

    # Alertmanager (protected)
    location /alertmanager/ {
        auth_basic "Alertmanager";
        auth_basic_user_file /etc/nginx/.htpasswd;
        proxy_pass http://127.0.0.1:9093/;
    }
}
EOF
    else
        # No domain - simple IP-based access
        cat > /etc/nginx/sites-available/observability << EOF
# Observability Stack Nginx Configuration (IP access only)

server {
    listen 80;
    server_name _;

    location / {
        proxy_pass http://127.0.0.1:3000;
        proxy_set_header Host \$host;
        proxy_set_header X-Real-IP \$remote_addr;
        proxy_set_header X-Forwarded-For \$proxy_add_x_forwarded_for;

        proxy_http_version 1.1;
        proxy_set_header Upgrade \$http_upgrade;
        proxy_set_header Connection "upgrade";
    }
}
EOF
    fi

    ln -sf /etc/nginx/sites-available/observability /etc/nginx/sites-enabled/
    rm -f /etc/nginx/sites-enabled/default

    # Create HTTP Basic Auth credentials for Prometheus/Alertmanager
    if [[ -n "${GRAFANA_DOMAIN:-}" ]] || [[ "$ssl_configured" == "true" ]]; then
        if [[ ! -f /etc/nginx/.htpasswd ]]; then
            log_info "Creating HTTP Basic Auth for Prometheus/Alertmanager..."

            # Generate random password if not set
            if [[ -z "${PROMETHEUS_AUTH_PASSWORD:-}" ]]; then
                PROMETHEUS_AUTH_PASSWORD=$(openssl rand -base64 16)
            fi

            # Create htpasswd file (username: admin)
            echo "${PROMETHEUS_AUTH_PASSWORD}" | htpasswd -ci /etc/nginx/.htpasswd admin
            chmod 640 /etc/nginx/.htpasswd
            chown root:www-data /etc/nginx/.htpasswd

            log_success "HTTP Basic Auth configured for Prometheus/Alertmanager"
            log_info "Username: admin"
            log_info "Password: ${PROMETHEUS_AUTH_PASSWORD}"

            # Save to installation info
            export PROMETHEUS_AUTH_PASSWORD
        else
            log_info "HTTP Basic Auth already configured (skipping)"
        fi
    fi

    nginx -t
    log_success "Nginx configuration generated"
}
